{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR using pytesseract and OpenCV by Hew Kok Sing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the cv2 and pytesseract library (install cv2 and tesseract before import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the location using pytesseract.pytesseract.tesseract_cmd attribute to set up the PATH environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image to the img variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('C:\\\\Users\\koksi\\\\Tesseract OCR\\\\test_v2\\\\test\\\\TEST_0030.jpg') #this is to get the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numerical python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the functions for image preprocessing\n",
    "\n",
    "# get grayscale image\n",
    "def get_grayscale(image): #to simplify the image\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def closing(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#resize image\n",
    "def resize_image(image):\n",
    "    scale_percent = 220 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    return cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#add padding to image\n",
    "def add_padding(image):\n",
    "    return cv2.copyMakeBorder(image, 50, 50, 100, 100, cv2.BORDER_CONSTANT, value=(255, 255, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addPadding = add_padding(img)\n",
    "gray = get_grayscale(addPadding)\n",
    "#dilate = dilate(gray)\n",
    "#noise = remove_noise(gray)\n",
    "#opening = opening(img)\n",
    "#closing = closing(gray)\n",
    "#resized = resize_image(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the text in the image in a window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pytesseract only accepts RGB value, openCV is in BGR\n",
    "#so we have to convert it before we send it to pytesseract library\n",
    "\n",
    "img = cv2.cvtColor(gray, cv2.COLOR_BGR2RGB) #convert BGR to RGB (just preprocess with grayscale)\n",
    "cv2.imshow('Result', gray) #display the image\n",
    "cv2.waitKey(0) #delay for infinityy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the text in the image to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom options\n",
    "custom_config = r'--oem 3 --psm 6' #this is a custom confiq oem 3 = engine mode 3-best accuracy #psm = page segmentation mode 6-default \n",
    "tessdata_dir_config = '--tessdata-dir \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "print(pytesseract.image_to_string(gray, config=tessdata_dir_config))\n",
    "#print(pytesseract.image_to_string(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the text - img_to_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pytesseract.image_to_boxes(gray, config=tessdata_dir_config)) #show each characters' bounding box information\n",
    "\n",
    "# x y width height "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display bounding box around characters - detecting characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hImg, wImg, _ = img.shape #obtain size info of the image\n",
    "\n",
    "boxes = pytesseract.image_to_boxes(img, config=tessdata_dir_config) #store each characters' bounding box information into a list\n",
    "\n",
    "for b in boxes.splitlines():\n",
    "    #print(b)\n",
    "    b = b.split(' ') #split each value by a space\n",
    "    #print(b)\n",
    "    x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4]) #convert string to int and assign to variable\n",
    "    cv2.rectangle(img, (x, hImg - y), (w, hImg - h), (0, 0, 255), 2) #create a rectangle bounding box\n",
    "    cv2.putText(img, b[0], (x + 250, hImg - y), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2) #put the text beside\n",
    "    \n",
    "cv2.imshow('Result', img) #display the image\n",
    "cv2.waitKey(0) #delay for infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display bounding box around words - detecting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hImg, wImg, _ = img.shape #obtain size info of the image\n",
    "\n",
    "boxes = pytesseract.image_to_data(img, config=tessdata_dir_config) #store each characters' bounding box information into a list\n",
    "#print(boxes)\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if x!=0:\n",
    "        b = b.split() #split each value\n",
    "        #print(b)\n",
    "        if len(b) == 12:\n",
    "            x, y, w, h = int(b[6]), int(b[7]), int(b[8]), int(b[9]) #convert string to int and assign to variable\n",
    "            cv2.rectangle(img, (x, y), (w + x, h + y), (0, 0, 255), 2) #create a rectangle bounding box\n",
    "            #cv2.putText(img, b[11], (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2) #put the text beside\n",
    "\n",
    "cv2.imshow('Result', img) #display the image\n",
    "cv2.waitKey(0) #delay for infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyOCR Text Recognition by Christopher Ewe Kah Thong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'file_path' #file path needed here, the test item must be inside the folder\n",
    "img = cv2.imread(img_path)\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(img, paragraph = True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "org = (225, 20) # where to show output text (x, y)\n",
    "\n",
    "for detection in result: \n",
    "    top_left = tuple([int(val) for val in detection[0][0]])\n",
    "    bottom_right = tuple ([int(val) for val in detection[0][2]])\n",
    "    text = detection[1]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    imgView = cv2.rectangle(img, top_left, bottom_right, (255, 0, 0), 1) #red color box \n",
    "    imgView = cv2.putText(img, text, org, font, 0.5, (0, 0, 0), 1, cv2.LINE_AA) #black output text, thickness = 1, font scale = 0.5\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(imgView)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras OCR Text Recognition by Kam Wei Ming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start, we need to pip install a package for running the overall of the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pip install keras-ocr ← put this code in Anaconda Navigator terminal to install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly we need to import two necessary package that we need in this project, matplotlib.pyplot will be use for visualizing the data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr as ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the code below keras-ocr will automatically download pretrained weights for the detector and recognizer.\n",
    "### For short, pipeline was initialized for create the text detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next line of code is easy to understand as the line already told to us. Which is the tools starting to read the image from the path of the image in our computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    ocr.tools.read(image) for image in [\n",
    "        \"C:\\\\Users\\\\Aaron\\\\Untitled Folder\\\\test\\\\TEST_0001.jpg\",\n",
    "        \"C:\\\\Users\\\\Aaron\\\\Untitled Folder\\\\test\\\\TEST_0002.jpg\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Come to the next coding line. The code is for showing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plt.imshow(images[0])\n",
    "plt.figure(figsize = (10, 20))\n",
    "plt.imshow(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is taking the pipeline object that created on the top and calling ocr tools recognize and passing the image from the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_groups = pipeline.recognize(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is to plot the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(images), figsize=(10, 20))\n",
    "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "    ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last, here will print the prediction of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "8da01e5a71448ea74f54d88afa8911010d1d12e23bc7e103d40d5def4a09152c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
